{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd696a45-a2de-49a7-bafb-4e6ca47ca0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nitish worked at exa.ai.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "[\"Nitish worked at exa.ai\"], embedding = OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = (\n",
    "{\"context\":retriever, \"question\": RunnablePassthrough()}\n",
    "| prompt | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"Where Nitish worked?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d88d35b3-9f08-462a-9d49-ae5693ee9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" Answert the question based only on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "Answer in the following language: {language}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"language\": itemgetter(\"language\")\n",
    "    }\n",
    "    | prompt\n",
    "    |model\n",
    "    |StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db65eca-a5a3-4ed2-ba6b-09bab0ba7c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नितीश ने एक्सा.एआई में काम किया।'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\":\"Where did Nitish work\", \"language\": \"Hindi!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640ba29d-dac6-4f74-acf1-bcc67bbdaef8",
   "metadata": {},
   "source": [
    "## Conversational Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "362dfa68-c0cf-4814-92d6-aef4455e7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import format_document\n",
    "from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string\n",
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b455244-30c3-46ef-ad65-476486b13362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939dbc90-cf5a-4b8a-9326-492b8f2836cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c59664c9-f5b2-49e1-ace7-1351f9866cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79cfd755-9e75-48d3-9990-4ce4fcdce691",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_template}\")\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [doc.page_content for doc in docs]\n",
    "    return document_separator.join(doc_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37042909-9be5-48cc-a321-6e33856535a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_inputs = RunnableParallel(\n",
    "    standalone_question = RunnablePassthrough.assign(\n",
    "        chat_history = lambda x: get_buffer_string(x[\"chat_history\"])\n",
    "    )\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | ChatOpenAI(temperature=0.4)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "_context = {\n",
    "    \"context\": itemgetter(\"standalone_question\") | retriever | _combine_documents,\n",
    "    \"question\": lambda x : x[\"standalone_question\"]\n",
    "}\n",
    "\n",
    "conversational_qa_chain = _inputs | _context | ANSWER_PROMPT | ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32004099-8ae8-4343-b887-9f2238ab6036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'RunnableParallel<standalone_question>Input',\n",
       " 'type': 'object',\n",
       " 'properties': {'question': {'title': 'Question', 'type': 'string'}}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_inputs.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4b54764-8ddd-478b-8e0c-d36f416720e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Nitish worked at exa.ai')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Where Nitish works\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef97ea55-7757-4c3c-ab90-e94be5c92136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Nitish worked at exa.ai.')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"where did Nitish work?\",\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c891443-0e58-4fc7-94d7-4f2516e7a61c",
   "metadata": {},
   "source": [
    "## With Memory and returning source documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2481cb0b-9ba3-475c-81e4-76fea31ec017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62b00b09-40fc-478e-b65a-66f8b223856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    return_messages = True, output_key=\"answer\", input_key=\"question\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e541e948-da5d-45dd-8ad6-435acbd49317",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_memory = RunnablePassthrough.assign(\n",
    "chat_history = RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
    "    )\n",
    "standalone_question = {\n",
    "    \"standalone_question\": {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    \"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"])\n",
    "    }\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | ChatOpenAI(temperature=0.4)\n",
    "    | StrOutputParser()\n",
    "}\n",
    "\n",
    "retrieved_documents = {\n",
    "    \"docs\": itemgetter(\"standalone_question\") | retriever,\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "}\n",
    "\n",
    "final_inputs = {\n",
    "    \"context\" : lambda x: _combine_documents(x[\"docs\"]),\n",
    "    \"question\" : lambda x: x[\"standalone_question\"]\n",
    "}\n",
    "\n",
    "answer = {\n",
    "\"answer\": final_inputs | ANSWER_PROMPT | ChatOpenAI(),\n",
    "    \"docs\": itemgetter(\"docs\")\n",
    "}\n",
    "\n",
    "final_chain = loaded_memory | standalone_question | retrieved_documents | answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b72f0756-1b5a-42d5-9f43-af19ed6004fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'where did Nitish work?', 'chat_history': []}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs = {\"question\": \"where did Nitish work?\"}\n",
    "# result = final_chain.invoke(inputs)\n",
    "# result\n",
    "loaded_memory.invoke({\"question\": \"where did Nitish work?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02e44d91-4ef8-4e25-9605-f6731add1e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'docs': RunnableLambda(itemgetter('standalone_question'))\n",
       " | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7f83e66f0370>),\n",
       " 'question': <function __main__.<lambda>(x)>}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c175c07f-ecac-4c8b-93b8-8e8c16839a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': AIMessage(content='There is no information provided about where Harrison worked.'),\n",
       " 'docs': [Document(page_content='Nitish worked at exa.ai')]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we add a step to load memory\n",
    "# This adds a \"memory\" key to the input object\n",
    "loaded_memory = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
    ")\n",
    "# Now we calculate the standalone question\n",
    "standalone_question = {\n",
    "    \"standalone_question\": {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"]),\n",
    "    }\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser(),\n",
    "}\n",
    "# Now we retrieve the documents\n",
    "retrieved_documents = {\n",
    "    \"docs\": itemgetter(\"standalone_question\") | retriever,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "# Now we construct the inputs for the final prompt\n",
    "final_inputs = {\n",
    "    \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "}\n",
    "# And finally, we do the part that returns the answers\n",
    "answer = {\n",
    "    \"answer\": final_inputs | ANSWER_PROMPT | ChatOpenAI(),\n",
    "    \"docs\": itemgetter(\"docs\"),\n",
    "}\n",
    "# And now we put it all together!\n",
    "final_chain = loaded_memory | standalone_question | retrieved_documents | answer\n",
    "\n",
    "inputs = {\"question\": \"where did harrison work?\"}\n",
    "result = final_chain.invoke(inputs)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c5afd-e773-412c-b7fa-4eaa42114923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
